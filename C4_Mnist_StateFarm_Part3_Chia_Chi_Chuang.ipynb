{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C4 MNIST HW Part 3: load PCA model, and try more different images on different classification\n",
    "\n",
    "Data Source: https://www.kaggle.com/c/state-farm-distracted-driver-detection\n",
    "\n",
    "State Farm Distracted Driver Images\n",
    "\n",
    "10 different labels/categories for each images\n",
    "\n",
    "Each color image is 640*480 22424 images in training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIL => Python Imaging Library\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readcsvfile(filename):\n",
    "    file_open=open(filename,'r')\n",
    "    lines_data=[]\n",
    "    for line in iter(file_open):\n",
    "        line=line.rstrip()\n",
    "        lines_data.append(line.split(','))\n",
    "    return lines_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hasThisFile(filename):\n",
    "    return os.path.isfile(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getJPGfileData(filename):\n",
    "    if hasThisFile(filename):\n",
    "        img=Image.open(filename)\n",
    "        img=img.convert('L')\n",
    "        return list(img.getdata())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtsinfo=readcsvfile('sfdd_train_data_rest_fv1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1, train2 = train_test_split(dtsinfo, test_size=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainImgFileDir='../dataSetImage/stateFarm_distractedDriver_all/imgs/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgsz=640*480\n",
    "trainsz=len(train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain1NP=np.empty((trainsz,imgsz),dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for itm in train1:\n",
    "    XTrain1NP[i].flat[:]=getJPGfileData(trainImgFileDir+itm[1]+'/'+itm[2])\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "import pickle\n",
    "filename = 'sfdd_pca_fv1.pkl'\n",
    "loaded_pca_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytrain1=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for itm in train1:\n",
    "    Ytrain1.append(int(itm[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytrain1NP=np.array(Ytrain1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "principalComponents = loaded_pca_model.transform(XTrain1NP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train3, train4 = train_test_split(train2, test_size=0.95)\n",
    "XTrain3NP=np.empty((len(train3),imgsz),dtype=np.int8)\n",
    "i=0\n",
    "for itm in train3:\n",
    "    XTrain3NP[i].flat[:]=getJPGfileData(trainImgFileDir+itm[1]+'/'+itm[2])\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "fif=open('sfdd_train_data_rest_fv2.csv','w')\n",
    "for x in train4:\n",
    "    fif.write(','.join(x)+'\\n')\n",
    "fif.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcts2 = loaded_pca_model.transform(XTrain3NP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytrain3=[]\n",
    "for itm in train3:\n",
    "    Ytrain3.append(int(itm[1][1]))\n",
    "Ytrain3NP=np.array(Ytrain3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.38      0.49      0.42       101\n",
      "          1       0.43      0.39      0.41       109\n",
      "          2       0.38      0.35      0.37       102\n",
      "          3       0.37      0.46      0.41       107\n",
      "          4       0.44      0.37      0.40        92\n",
      "          5       0.50      0.45      0.47        94\n",
      "          6       0.37      0.39      0.38        93\n",
      "          7       0.31      0.26      0.28        69\n",
      "          8       0.26      0.22      0.24        72\n",
      "          9       0.31      0.34      0.32        74\n",
      "\n",
      "avg / total       0.38      0.38      0.38       913\n",
      "\n",
      "[[49  6  4 14  5  2  8  2  6  5]\n",
      " [12 42  7  6  4 10 11  6  6  5]\n",
      " [11  6 36 15  2  3  5  6 13  5]\n",
      " [ 9  4  9 49  9  5  8  7  2  5]\n",
      " [ 6  7  8 13 34  6  6  5  3  4]\n",
      " [10  8  4  2  7 42  7  3  3  8]\n",
      " [ 8  6  9  4  3  4 36  4  8 11]\n",
      " [ 9  5  6  7  5  4  6 18  2  7]\n",
      " [ 6  7  8 12  2  2  7  6 16  6]\n",
      " [10  6  4  9  6  6  4  1  3 25]]\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(principalComponents,Ytrain1NP)\n",
    "print(model)\n",
    "# make predictions\n",
    "expected = Ytrain3NP\n",
    "predicted = model.predict(pcts2)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.41      0.46      0.43       101\n",
      "          1       0.45      0.38      0.41       109\n",
      "          2       0.28      0.19      0.22       102\n",
      "          3       0.26      0.24      0.25       107\n",
      "          4       0.52      0.40      0.45        92\n",
      "          5       0.47      0.33      0.39        94\n",
      "          6       0.30      0.52      0.38        93\n",
      "          7       0.28      0.39      0.33        69\n",
      "          8       0.23      0.32      0.27        72\n",
      "          9       0.41      0.27      0.33        74\n",
      "\n",
      "avg / total       0.37      0.35      0.35       913\n",
      "\n",
      "[[46  9  7  9  3  1  8  5  5  8]\n",
      " [ 3 41  9 14  0  1 16 14 11  0]\n",
      " [ 3 11 19 11  2  2 21 14 16  3]\n",
      " [19  8  8 26 17  6  8  3  7  5]\n",
      " [ 5  5  5 11 37  6  7  6  7  3]\n",
      " [14  5  1  9  4 31 14  7  8  1]\n",
      " [ 2  9  6  5  1  4 48  7 10  1]\n",
      " [ 5  2  3  6  1  1 13 27  8  3]\n",
      " [ 6  1  5  1  3 10 12  6 23  5]\n",
      " [ 8  0  4  9  3  4 14  7  5 20]]\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Classification\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()\n",
    "model.fit(principalComponents,Ytrain1NP)\n",
    "print(model)\n",
    "# make predictions\n",
    "expected = Ytrain3NP\n",
    "predicted = model.predict(pcts2)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.78      0.66       101\n",
      "          1       0.60      0.75      0.67       109\n",
      "          2       0.53      0.69      0.60       102\n",
      "          3       0.61      0.62      0.61       107\n",
      "          4       0.64      0.59      0.61        92\n",
      "          5       0.80      0.64      0.71        94\n",
      "          6       0.67      0.73      0.70        93\n",
      "          7       0.92      0.64      0.75        69\n",
      "          8       0.86      0.50      0.63        72\n",
      "          9       0.71      0.43      0.54        74\n",
      "\n",
      "avg / total       0.67      0.65      0.65       913\n",
      "\n",
      "[[79  7  1  5  2  0  4  0  1  2]\n",
      " [ 8 82 11  3  2  0  0  1  0  2]\n",
      " [ 1 14 70  3  1  2  8  0  2  1]\n",
      " [ 9  5 11 66 11  3  1  0  0  1]\n",
      " [11  0  2 20 54  1  2  0  0  2]\n",
      " [13  6  4  2  4 60  4  0  0  1]\n",
      " [ 0  8 11  0  0  5 68  0  0  1]\n",
      " [ 4  3  8  1  0  2  4 44  2  1]\n",
      " [ 3  4 10  1  4  1  8  3 36  2]\n",
      " [12  8  4  8  6  1  2  0  1 32]]\n"
     ]
    }
   ],
   "source": [
    "# Knn- classification\n",
    "# k-Nearest Neighbor Classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(principalComponents,Ytrain1NP)\n",
    "print(model)\n",
    "# make predictions\n",
    "expected = Ytrain3NP\n",
    "predicted = model.predict(pcts2)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=10, solver='lbfgs', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.70      0.63       101\n",
      "          1       0.50      0.47      0.49       109\n",
      "          2       0.56      0.52      0.54       102\n",
      "          3       0.69      0.61      0.65       107\n",
      "          4       0.49      0.51      0.50        92\n",
      "          5       0.66      0.50      0.57        94\n",
      "          6       0.49      0.48      0.49        93\n",
      "          7       0.60      0.65      0.63        69\n",
      "          8       0.53      0.57      0.55        72\n",
      "          9       0.47      0.55      0.51        74\n",
      "\n",
      "avg / total       0.56      0.55      0.55       913\n",
      "\n",
      "[[71  9  2  3  2  1  3  2  1  7]\n",
      " [ 9 51 17  1  7  1  6  4  5  8]\n",
      " [ 7  8 53  2  3  3 14  4  6  2]\n",
      " [10  2  1 65 12  3  2  5  1  6]\n",
      " [12  3  3  9 47  5  4  3  1  5]\n",
      " [ 5  6  1  0  9 47  6  5  3 12]\n",
      " [ 3  7  6  1  6  4 45  3 16  2]\n",
      " [ 1  3  9  0  0  3  4 45  3  1]\n",
      " [ 1  6  3  7  3  1  4  3 41  3]\n",
      " [ 6  6  0  6  7  3  3  1  1 41]]\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(solver = 'lbfgs',random_state=10)\n",
    "model.fit(principalComponents,Ytrain1NP)\n",
    "print(model)\n",
    "# make predictions\n",
    "expected = Ytrain3NP\n",
    "predicted = model.predict(pcts2)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
